{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3075e9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "from langchain_community.document_loaders import ToMarkdownLoader, ReadTheDocsLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, MarkdownHeaderTextSplitter, MarkdownTextSplitter\n",
    "from langchain.schema import Document\n",
    "import re\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "82adcb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "def preprocess_markdown(md_text: str):\n",
    "    \"\"\"\n",
    "    Làm s?ch và chu?n hóa n?i dung Markdown:\n",
    "    - Gi? nguyên tiêu d?, b?ng, code block\n",
    "    - Lo?i b? hình ?nh và ph?n tham kh?o\n",
    "    \"\"\"\n",
    "    # 1?? Lo?i b? hình ?nh ![...](...)\n",
    "    md_text = re.sub(r'!\\[.*?\\]\\(.*?\\)', '', md_text)\n",
    "\n",
    "    # 2?? Lo?i b? liên k?t tr?n [text](url) ? gi? l?i text\n",
    "    md_text = re.sub(r'\\[(.*?)\\]\\(.*?\\)', r'\\1', md_text)\n",
    "\n",
    "    # 3?? Lo?i b? ph?n References (n?u có)\n",
    "    md_text = re.split(r'(?i)^#+\\s*references', md_text)[0]\n",
    "\n",
    "    # 4?? Chu?n hóa nhi?u dòng tr?ng\n",
    "    md_text = re.sub(r'\\n{3,}', '\\n\\n', md_text)\n",
    "\n",
    "    return md_text.strip()\n",
    "\n",
    "\n",
    "def split_markdown_into_sections(md_text: str):\n",
    "    \"\"\"\n",
    "        split document according to header using MardownHeaderTextSplitter\n",
    "    \"\"\"\n",
    "    headers_to_split_on = [\n",
    "        (\"#\", \"Header 1\"),\n",
    "        (\"##\", \"Header 2\"),\n",
    "        (\"###\", \"Header 3\"),\n",
    "    ]\n",
    "    markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "        headers_to_split_on=headers_to_split_on,\n",
    "        return_each_line=False,\n",
    "        strip_headers=False\n",
    "    )\n",
    "    markdown_splits = markdown_splitter.split_text(md_text)\n",
    "    return markdown_splits\n",
    "\n",
    "\n",
    "def create_chunks(md_text: str, source_path: str, chunk_size: int=512, chunk_overlap=30):\n",
    "    \"\"\"\n",
    "        create chunks by apply recursive splitter method within markdown_split\n",
    "    \"\"\"\n",
    "    # md_text = preprocess_markdown(md_text)\n",
    "    markdown_splits = split_markdown_into_sections(md_text)\n",
    "    # text_splitter = RecursiveCharacterTextSplitter(\n",
    "    #     separators=[\",\", \",\"],\n",
    "    #     chunk_size=chunk_size,\n",
    "    #     chunk_overlap=chunk_overlap\n",
    "    # )\n",
    "    # splits = text_splitter.split_documents(markdown_splits)\n",
    "\n",
    "    return markdown_splits\n",
    "\n",
    "    \n",
    "\n",
    "# ?? Ví d? s? d?ng\n",
    "if __name__ == \"__main__\":\n",
    "    path = \"/data/AIRACE/training_out/Public003/main.md\"\n",
    "    md_text = Path(path).read_text(encoding=\"utf-8\")\n",
    "\n",
    "    md_splits = create_chunks(md_text, source_path=path)\n",
    "    print(len(md_splits))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "591047f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chonkie import Pipeline\n",
    "from chonkie import RecursiveRules, RecursiveLevel\n",
    "from chonkie import TokenChunker, OverlapRefinery\n",
    "\n",
    "\n",
    "rules = RecursiveRules(\n",
    "    levels=[\n",
    "        RecursiveLevel(delimiters=[\"\\n\\n\"], include_delim=\"prev\"),\n",
    "        RecursiveLevel(delimiters=[\"\\n\"], include_delim=\"prev\"),\n",
    "        RecursiveLevel(delimiters=[\".\"], include_delim=\"prev\"),\n",
    "        RecursiveLevel(delimiters=[\",\"], include_delim=\"prev\"),\n",
    "        RecursiveLevel(whitespace=False)\n",
    "    ]\n",
    ")\n",
    "# Build and execute pipeline\n",
    "doc = (Pipeline()\n",
    "    .fetch_from(\"file\", path=\"/data/AIRACE/training_out/Public003/main.md\")\n",
    "    .process_with(\"markdown\")\n",
    "    .chunk_with(\"recursive\", chunk_size=512)\n",
    "    .refine_with(\"overlap\", context_size=50, mode=\"recursive\", rules=rules)\n",
    "    .run())\n",
    "\n",
    "# Access chunks\n",
    "# print(f\"Created {len(doc.chunks)} chunks\")\n",
    "# for i, chunk in enumerate(doc.chunks):\n",
    "#     print(f\"=========== chunk {i} =============\")\n",
    "#     print(chunk.text)\n",
    "\n",
    "# print(f\"Found {len(doc.tables)} tables\")\n",
    "# print(f\"Found {len(doc.code)} code blocks\")\n",
    "# print(f\"Found {len(doc.images)} images\")\n",
    "# print(f\"Created {len(doc.chunks)} chunks\")\n",
    "# print(type(doc))\n",
    "\n",
    "\n",
    "overlap_refinery = OverlapRefinery(\n",
    "    tokenizer=\"character\",\n",
    "    context_size=0.5,\n",
    "    method=\"suffix\",\n",
    "    merge=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10a65d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Chunk(text='# Public_003\n",
      "\n",
      "_Dịch máy là một trong những hướng nghiên cứu quan trọng trong xử lý ngôn ngữ tự nhiên. Trong những năm gần đây, dịch máy nơ ron đã và đang được nghiên cứu phổ biến hơn trong cộng đồng dịch máy vì hiện tại nó cho chất lượng dịch tốt hơn so với phương pháp dịch máy thống kê truyền thống. Tuy nhiên, dịch máy nơ ron lại cần lượng lớn dữ liệu song ngữ để huấn luyện. Hệ dịch sẽ cho chất lượng bản dịch tốt hơn khi nó được thử nghiệm trong cùng miền với miền dữ liệu mà nó được huấn luyện, ngược lại thì chất lượng bản dịch sẽ bị sụt giảm, mức độ sụt giảm phụ thuộc vào mức độ khác biệt giữa dữ liệu miền huấn luyện và dữ liệu miền thử nghiệm. Hiện nay, các kĩ thuật thích ứng miền cho dịch máy nơ ron đã được công bố chủ yếu được thực hiện trên một số cặp ngôn ngữ phổ biến giàu tài nguyên, và chưa có nhiều nghiên cứu đã được công bố về thích ứng miền trong dịch máy nơ ron cho cặp ngôn ngữ Anh - Việt._\n",
      "\n",
      "_Trong bài báo này, chúng tôi đề xuất một phương pháp thích ứng miền mới cho dịch máy nơ ron, áp dụng cho cặp ngôn ngữ Anh - Việt. Ý tưởng chính của bài báo là kết hợp dữ liệu đơn ngữ ngoài miền ở ngôn ngữ nguồn (tiếng Anh) với bản dịch của nó ở ngôn ngữ đích (tiếng Việt) để làm dữ liệu huấn luyện hệ dịch. Các thực nghiệm đã chứng minh rằng phương pháp chúng tôi đề xuất dễ thực hiện, khai thác được những ưu điểm của dữ liệu đơn ngữ như luôn có sẵn, chi phí xây dựng thấp và đặc biệt là chất lượng của hệ dịch được và tăng 2,21 điểm BLEU trong thử nghiệm của chúng tôi._\n",
      "\n",
      "# Nội dung chính\n",
      "\n",
      "## GIỚI THIỆU\n",
      "\n",
      "Mục tiêu của dịch máy là nghiên cứu các phương pháp, kĩ thuật để xây dựng được một hệ thống có thể dịch tự động các câu từ một ngôn ngữ tự nhiên này sang ngôn ngữ khác, đây là một trong những hướng nghiên cứu quan trọng trong trí tuệ nhân tạo, đặc biệt trong xử lý ngôn ngữ tự nhiên. Dịch máy là một nhánh nhỏ của xử lý ngôn ngữ tự nhiên, và vì xử lý ngôn ngữ tự nhiên là lĩnh vực liên ngành giữa khoa học máy tính và ngôn ngữ học, chính đặc điểm đó nên các nghiên cứu về dịch máy có thể chia thành hai nhóm phương pháp chính là các phương pháp dựa trên luật và các phương pháp dựa trên ngữ liệu. Trong số đó, các phương pháp dựa trên ngữ liệu có thể được chia thành các phương pháp dựa trên thống kê và các phương pháp dựa trên ví dụ. Trong những năm gần đây, với sự phát triển của internet, dịch máy đã đạt được những kết quả tốt cả về học thuật và trong công nghiệp.\n",
      "\n",
      "Gần đây, các nghiên cứu về dịch máy đã dịch chuyển dần từ các phương pháp dịch thống kê _(Statistical Machine Translation)_ sang dịch máy nơ ron _(Neural Machine Translation)_ , hiện tại đây được coi là một hệ dịch cho chất lượng dịch vượt trội so với các phương pháp truyền thống trước đây. Tuy nhiên, các hệ dịch nơ ron lại yêu cầu nhiều dữ liệu song ngữ hơn để huấn luyện hệ dịch, điều này ít ảnh hưởng tới chất lượng bản dịch của hệ dịch dành cho các cặp ngôn ngữ phổ biến và giàu tài nguyên nhưng nó lại là thách thức lớn đối với các cặp ngôn ngữ có ít tài nguyên.\n",
      "\n",
      "Thông thường, hệ dịch được huấn luyện trên lượng lớn dữ liệu song ngữ và dữ liệu đơn ngữ của ngôn ngữ đích đối với dịch máy thống kê và dữ liệu song ngữ đối với dịch máy nơ ron, trong bản thân những dữ liệu huấn luyện này có thể bao gồm các chủ đề đồng nhất hoặc không đồng nhất và thường thì mỗi chủ đề đó sẽ có tập các từ thuật ngữ riêng biệt. Chất lượng của bản dịch phụ thuộc rất lớn vào dữ liệu huấn luyện, nếu miền dữ liệu huấn luyện và miền thử nghiệm giống nhau hoặc có sự tương đồng càng lớn thì chất lượng bản dịch thu được sẽ càng tốt so với việc miền dữ liệu dùng để huấn luyện và miền thử nghiệm dặc biệt khác nhau hoặc có ít sự tương đồng hơn. Ví dụ, nếu hệ dịch được huấn luyện với dữ liệu thuộc miền tin tức thì khi dịch các văn bản cũng thuộc miền tin tức sẽ cho chất lượng bản dịch tốt, nhưng nếu đem hệ dịch đó để dịch các văn bản thuộc miền khác với miền tin tức như miền y tế, tin học, luật, v.v... thì chất lượng của bản dịch sẽ bị giảm đột ngột, mức độ giảm tùy thuộc vào mức độ tương đồng của miền dữ liệu dùng để huấn luyện hệ dịch so với miền dữ liệu dùng để thử nghiệm.\n",
      "\n",
      "Các miền dữ liệu song ngữ trong thực tế thường rất hiếm hoặc bị giới hạn về số lượng, đặc biệt đối với các cặp ngôn ngữ ít phổ biến như ngôn ngữ Anh - Việt, nhất là các miền dữ liệu đặc thù. Để đạt được chất lượng bản dịch tốt nhất thì dữ liệu huấn luyện phải thuộc cùng một miền, cùng một thể loại và cùng một phong cách với miền mà hệ dịch được áp dụng nhưng tế để có được lượng dữ liệu huấn luyện đủ lớn trong mỗi miền mà thỏa mãn những đặc điểm trên là rất khó, hoặc cần phải trả một chi phí rất lớn để xây dựng dữ liệu huấn luyện. Vì vậy, trong bài báo này chúng tôi trình bày một phương pháp thích ứng miền mới cho dịch máy nơ ron, áp dụng cho cặp ngôn ngữ Anh - Việt với chiều dịch từ tiếng Anh sang tiếng Việt. Các thử nghiệm được tiến hành trên hai miền dữ liệu là miền tổng quan và miền pháp lý, chất lượng dịch trên miền tổng quan làm cơ sở để so sánh, đánh giá chất lượng hệ dịch khi được áp dụng trong miền pháp lý cũng như đánh giá hiệu quả của phương pháp được đề xuất. Qua thử nghiệm cho thấy, phương pháp này dễ thực hiện, tận dụng được lượng lớn dữ liệu đơn ngữ luôn có sẵn với chi phí thấp và khả quan khi đã cải tiến được chất lượng bản dịch tăng 2,21 điểm BLEU [6] _(từ 22,17 điểm lên 24,38 điểm)._\n",
      "\n",
      "Bài báo này được trình bày cấu trúc như sau: Tiếp theo, phần 2 sẽ giới thiệu các nghiên cứu trước đây có liên quan; phần 3 trình bày tổng quan phương pháp chúng tôi đề xuất; phần 4 trình bày các thử nghiệm và các kết quả; phần 5 là kết luận và hướng phát triển; và cuối cùng phần 6 là một số tài liệu tham khảo.\n",
      "\n",
      "## CÁC NGHIÊN CỨU LIÊN QUAN\n",
      "\n",
      "Những năm gần đây, thích ứng miền là một trong những chủ đề đã giành được rất nhiều sự quan tâm của các nhà khoa học trên thế giới. Hiện nay, đã có nhiều phương pháp được đề xuất để thích ứng cho dịch máy thống kê cũng như dịch máy nơ ron, nhưng các đề xuất đó chủ yếu áp dụng cho một số cặp ngôn ngữ phổ biến trên thế giới như Anh - Pháp, Anh - Nhật, Anh - Tây Ban Nha,... Các phương pháp đã đề xuất được công bố đều thuộc một trong ba hướng chính, đó là: (1) bổ sung thêm nhiều dữ liệu hơn; (2) các kĩ thuật để có dữ liệu chất lượng hơn và (3) các kĩ thuật để có mô hình chất lượng hơn. Với hướng tiếp cận (1) và (2), đã có nhiều công bố đề xuất sử dụng dữ liệu đơn ngữ để cải tiến chất lượng hệ dịch khi dịch trong miền mới, các đề xuất này chủ yếu đã được chứng minh bằng thực nghiệm trong dịch máy thống kê, và chưa có nhiều đề xuất đối với dịch máy nơ ron.\n",
      "\n",
      "Trong [2], kỹ thuật thích ứng giữa các miền được đề xuất để áp dụng cho dịch máy thống kê dựa vào cụm từ về nhiệm vụ Europarl1 [3], để dịch các bình luận tin tức từ tiếng Pháp sang tiếng Anh. Cụ thể, một phần nhỏ dữ liệu song ngữ miền được khai thác để thích ứng mô hình ngôn ngữ và mô hình dịch bằng kỹ thuật nội suy tuyến tính. Việc thích ứng các mô hình dịch, mô hình đảo trật tự từ được thực hiện qua việc sinh thêm dữ liệu song ngữ từ dữ liệu đơn ngữ.\n",
      "\n",
      "Công bố [9] đã đề xuất một số phương pháp thích ứng khá phức tạp dựa trên việc bổ sung thêm dữ liệu song ngữ được tổng hợp từ các tập dữ liệu dùng để tối ưu tham số và thử nghiệm. Ngoài ra, trong [10], đề xuất một phương pháp nhằm khai thác nguồn tài nguyên dữ liệu đơn ngữ miền bằng cách tổng hợp dữ liệu song ngữ từ việc dịch dữ liệu đơn ngữ miền sang ngôn ngữ đích. Phương pháp này chủ yếu liên quan đến kĩ thuật được đề xuất trong [2] nhưng khác nhau ở dữ liệu dùng để thích ứng miền, cụ thể ở [10] chỉ sử dụng dữ liệu đơn ngữ miền.\n",
      "\n",
      "Các đề xuất trên được công bố cho dịch máy thống kê. Tuy nhiên, năm 2016 có công bố [11] đã đề xuất thích ứng miền cho dịch máy nơ ron dựa vào sinh dữ liệu song ngữ cho hệ dịch bằng việc dịch ngược các dữ liệu đơn ngữ trong miền đích. Trong bài báo này, phương pháp chúng tôi đề xuất có phần giống với phương pháp [9] vì chúng tôi có sử dụng thêm một tập dữ liệu miền pháp lý để tối ưu tham số của hệ dịch cơ sở theo định hướng miền đích, nhưng cũng liên quan nhiều đến phương pháp được đề xuất trong [10] và [11].\n",
      "\n",
      "Nhìn chung, các phương pháp về thích ứng miền nói chung cho dịch máy đã được công bố khá phức tạp, thử nghiệm công phu và sử dụng nhiều mô hình toán học. Tuy nhiên, các thử nghiệm mới chỉ áp dụng cho một số cặp ngôn ngữ phổ biến như Anh - Pháp, Anh - Nhật, Anh - Tây Ban Nha,... Hiện vẫn chưa có công bố nào áp dụng cho cặp ngôn ngữ Anh - Việt.\n",
      "\n",
      "## PHƯƠNG PHÁP ĐỀ XUẤT\n",
      "\n",
      "### Tổng quan về dịch máy nơ ron\n",
      "\n",
      "Đối với phương pháp dịch máy truyền thống như dịch máy thống kê dựa vào cụm thì hệ dịch thực hiện phân tách câu nguồn thành nhiều từ hoặc cụm từ riêng biệt, sau đó dịch tuần tự từng từ hoặc cụm từ một rồi sắp xếp lại trật tự các từ theo đúng trật tự trong ngôn ngữ đích. Vì thế, nên bản dịch không được trôi chảy và các dịch này không giống như cách con người dịch, để dịch, chúng ta sẽ đọc trọn vẹn một câu nguồn, hiểu ý nghĩa của nó rồi mới tiến hành dịch câu đó sang ngôn ngữ đích. Dịch máy nơ ron thực hiện dịch tương tự như cách của con người.\n",
      "\n",
      "|<image_n>|\n",
      "\n",
      "_**Hình 1.** Kiến trúc Encoder - Decoder_\n",
      "\n",
      "Cụ thể, đầu tiên hệ dịch nơ ron sử dụng bộ mã hóa _(Encoder)_ để đọc toàn bộ câu nguồn và mã hóa nó dưới dạng một vectơ biểu diễn ý nghĩa. Sau đó, bộ giải mã _(Decoder)_ sẽ đọc và giải mã vec tơ biểu diễn câu nguồn này để sinh ra bản dịch tương ứng sang ngôn ngữ đích, quá trình mã hóa - giải mã được minh họa như ở hình 1 và hình 2 [5]. Theo cách dịch này, hệ dịch nơ ron có thể giải quyết được vấn đề dịch cục bộ trong phương pháp dịch dựa vào cụm truyền thống, đó là: nó có thể nắm bắt được các phụ thuộc xa hơn trong các ngôn ngữ và tạo ra các bản dịch trôi chảy hơn nhiều so với hệ dịch thống kê dựa vào cụm truyền thống.\n",
      "\n",
      "**Bộ mã hóa -** Bộ mã hóa đọc câu nguồn _X = (x1, x2, …,xT)_ và chuyển đổi nó thành một chuỗi các trạng thái ẩn _h = (h1, h2,…,hT)_ sử dụng mạng nơ ron hồi quy hai chiều _(bi-directional RNN)_. Tại mỗi thời điểm t, trạng thái ẩn ht được xác định như là một kết hợp các trạng thái ẩn của mạng nơ ron hồi quy theo chiều xuôi _(forward RNN)_ và theo chiều ngược\n",
      "$$\n",
      "\\overrightarrow{h_t} = \\mathrm{RNN}(x_t, \\overrightarrow{h_{t-1}}), \\quad \\overleftarrow{h_t} = \\mathrm{RNN}(x_t, \\overleftarrow{h_{t+1}})\n",
      "$$\n",
      "\n",
      "_(backward RNN)_ $[\\overrightarrow{h_t};\\overleftarrow{h_t}]$ với điều kiện\n",
      "**Bộ giải mã -** Bộ giải mã sử dụng mạng nơ ron hồi quy khác để sinh ra bản dịch _Y = (y1, y2, …,yT’)_ dựa trên các trạng thái ẩn h được sinh bởi bộ mã hóa. Tại mỗi thời điểm i, xác suất có điều kiện của mỗi từ yi trong tập từ vựng _Vy_ của ngôn ngữ đích được tính bởi công thức:\n",
      "\n",
      "$$\n",
      "P(y_i|y < i, h)=g(y_{i-1}, z_i, c_i)\n",
      "$$\n",
      "\n",
      "_v_ ới điều kiện zi là trạng thái ẩn ith của bộ giải mã, và được tính dựa vào trạng thái ẩn trước zi-1, từ trước yi-1 và vectơ ngữ cảnh nguồn ci: $Z_i= RNN(zi-1, yi-1, ci).$\n",
      "\n",
      "', token_count=10724, start_index=0, end_index=10724), Chunk(text='\n",
      "\n",
      "tran ngoc du\n",
      "\n",
      "### Phương pháp đề xuất\n",
      "\n",
      "Trong thực tế, dữ liệu song ngữ thường không có sẵn, đặc biệt đối với các miền dữ liệu thuộc các lĩnh vực, chuyên ngành đặc thù, còn nếu muốn xây dựng dữ liệu song ngữ cho từng miền thì chi phí phải trả sẽ rất cao nhưng dữ liệu đơn ngữ thì lại luôn có sẵn với bất cứ miền dữ liệu nào. Trong dịch máy, dữ liệu đơn ngữ thường được dùng để làm mịn câu, khiến bản dịch của câu trôi chảy hơn và đọc lên thấy tự nhiên nhất. Dữ liệu đơn ngữ cũng đã được chứng minh có nhiều lợi ích trong việc cải tiến chất lượng dịch của cả hệ dịch máy thống kê và dịch máy nơ ron, đặc biệt trong nhiệm vụ thích ứng trong trường hợp nguồn tài nguyên bị hạn chế, nguồn dữ liệu song ngữ không đủ lớn. Hiện nay, cũng đã có một số đề xuất sử dụng dữ liệu đơn ngữ cho việc cải tiến chất lượng dịch, trong đó có đề xuất sinh dữ liệu song ngữ từ dữ liệu đơn ngữ cho dịch máy nhưng chưa có đề xuất, thử nghiệm hay khảo sát nào được công bố về sử dụng dữ liệu đơn ngữ để thích ứng miền áp dụng cho cặp ngôn ngữ Anh – Việt.\n",
      "Như đã trình ở phần 2, phương pháp chúng tôi đề xuất có liên quan tới các công bố [9]; [10] và [11]. Theo [11], để sinh dữ liệu song ngữ thì việc dịch theo chiều ngược là cũng một giải pháp để có thể tận dụng được nguồn dữ liệu đơn ngữ miền. Để dịch theo chiều ngược hay theo chiều xuôi thì khá đơn giản và dễ áp dụng vì nó không yêu cầu phải thay đổi các thuật toán huấn luyện của hệ dịch.\n",
      "Xuất phát từ ý tưởng trên, chúng tôi đề xuất một phương pháp mới để sinh dữ liệu song ngữ cho nhiệm vụ thích ứng miền áp dụng cho cặp ngôn ngữ Anh - Việt với chiều dịch từ Anh sang Việt, phương pháp của chúng tôi chỉ sử dụng dữ liệu đơn ngữ trong miền đích của ngôn ngữ đích. Phương pháp của chúng tôi khác với công bố trong [9]; [10] vì các công bố này chỉ thực nghiệm, áp dụng cho dịch máy thống kê dựa vào cụm còn phương pháp của chúng tôi là áp dụng cho dịch máy nơ ron. Ngoài ra, công bố [11] cũng khá liên quan tới phương pháp của chúng tôi khi cũng áp dụng cho dịch máy nơ ron, nhưng sử dụng kĩ thuật dịch ngược. Còn phương pháp của chúng tôi, cùng với các thử nghiệm, đánh giá hệ dịch dựa trên cách dịch xuôi dữ liệu đơn ngữ trong miền đích của ngôn ngữ đích. Phương pháp chúng tôi đề xuất được mô tả như hình 3, gồm 3 giai đoạn:\n",
      "\n",
      "  * **Giai đoạn 1** : Giai đoạn này chúng tôi sử dụng dữ liệu song ngữ Anh – Việt thuộc miền tổng quan để huấn luyện một hệ dịch nơ ron làm cơ sở để so sánh, đánh giá hiệu quả của phương pháp chúng tôi đề xuất _(đặt tên là **Baseline NMT** như mô tả trong Hình 3 **,** trong các thử nghiệm gồm các hệ dịch Baseline_L và Baseline_G)_;\n",
      "\n",
      "\n",
      "  * **Giai đoạn 2** : Sau khi đã có hệ dịch Baseline NMT ở giai đoạn 1, chúng tôi sử dụng hệ dịch này để dịch các văn bản đơn ngữ thuộc miền pháp lý trong tiếng Anh sang ngôn ngữ đích là tiếng Việt;\n",
      "\n",
      "  * **Giai đoạn 3** : Sau khi có kết quả dịch ở giai đoạn 2, chúng tôi sử dụng kết quả dịch này kết hợp với các văn bản đơn ngữ bằng tiếng Anh ở giai đoạn 2 để huấn luyện một hệ dịch nơ ron khác _(đặt tên là **Adaptation NMT** như mô tả trong Hình 3, trong các thử nghiệm là hệ dịch **Adapt_System** )_, hệ dịch này được sử dụng để cải tiến chất lượng dịch của các văn bản thuộc miền pháp lý.\n",
      "\n",
      "\n",
      "Bằng thực nghiệm, các kết quả so sánh thông qua cách đánh giá bằng điểm BLEU [6] đã chỉ ra rằng phương pháp chúng tôi đề xuất là cách tiếp cận khả quan, dễ thực hiện và đã cho kết quả dịch cải tiến hơn so với hệ dịch cơ sở ban đầu.\n",
      "\n",
      "## THỰC NGHIỆM VÀ KẾT QUẢ\n",
      "\n",
      "Để so sánh, đánh giá phương pháp đề xuất, chúng tôi tiến hành huấn luyện ba hệ dịch nơ ron, lần lượt _là **(1) Baseline_G**_ \\- là hệ dịch cơ sở được huấn luyện với tập dữ liệu huấn luyện và tập tối ưu tham số _(tập dữ liệu G_train và tập dữ liệu G_val)_ cùng thuộc miền tổng quan; _**(2) Baseline_L**_ \\- là hệ dịch được huấn luyện với tập dữ liệu huấn luyện thuộc miền tổng quan _(G_train)_ , còn tập tối ưu tham số thuộc miền luật _(L_val)_ ; _**(3) Adapt_System**_ \\- là hệ dịch được huấn luyện với dữ liệu song ngữ được tổng hợp ở giai đoạn 2 của hình 3 và dữ liệu tối ưu tham số thuộc miền luật _(L_val)_.\n",
      "\n",
      "This table shows the performance metrics for various YOLOv5 models trained on the COCO dataset.\n",
      "\n",
      "', token_count=4163, start_index=11777, end_index=15940), Chunk(text='\n",
      "\n",
      "Tiếp theo, chúng tôi sẽ mô tả về các tập dữ liệu, các bước tiền xử lý đối với dữ liệu huấn luyện của từng hệ dịch trên, đồng thời chúng tôi cũng trình bày cụ thể các bước thực nghiệm và kết quả tương ứng.\n",
      "\n",
      "### Dữ liệu\n",
      "\n",
      "Để huấn luyện hệ dịch, trong các thử nghiệm của chúng tôi có hai loại dữ liệu miền khác nhau, ở góc độ bài toán mà chúng tôi giải quyết đó là tận dụng dữ liệu đơn ngữ thuộc miền cần dịch và một hệ dịch có sẵn thuộc miền tổng quan để nâng cao chất lượng dịch theo miền _(miền pháp lý trong các thực nghiệm của chúng tôi)_. Để thống nhất, chúng tôi gọi dữ liệu thuộc miền tổng quan để huấn luyện hệ dịch là dữ liệu trong miền và dữ liệu không thuộc miền huấn luyện là dữ liệu ngoài miền.\n",
      "\n",
      "### Thống kê dữ liệu\n",
      "\n",
      "  1. _Dữ liệu trong miền:_ Chúng tôi sử dụng tập dữ liệu được cung cấp bởi hội nghị IWSLT 20152, tập dữ liệu này thuộc miền tổng quan gồm 131.000 cặp câu song ngữ tiếng Anh - tiếng Việt dành cho nhiệm vụ về dịch máy, tập dữ liệu này\n",
      "\n",
      "\n",
      "được gọi là tập _**G_train**_ và được sử dụng để huấn luyện các hệ dịch cơ sở _(Baseline_G và Baseline_L)_. Để tối ưu các tham số của hệ dịch trong miền tổng quan, chúng tôi sử dụng tập dữ liệu gồm 745 cặp câu song ngữ thuộc miền tổng quan và gọi là tập _**G_val**_. Để đánh giá chất lượng của các hệ dịch khi dịch trong miền tổng quan, chúng tôi sử dụng 1.046 cặp câu song ngữ Anh – Việt thuộc miền tổng quan.\n",
      "\n",
      "  2. _Dữ liệu ngoài miền:_ Chúng tôi sử dụng 100.000 câu đơn ngữ tiếng Anh thuộc miền pháp lý và dùng hệ dịch cơ sở Basline_NMT theo mô tả ở giai đoạn 2 của hình 3 để dịch nhằm tạo ra bản dịch gồm 100.000 câu tiếng Việt tương ứng. Để đánh giá chất lượng của các hệ dịch trong miền pháp lý, chúng tôi sử dụng 2.000 cặp câu song ngữ Anh - Việt cùng thuộc miền pháp lý.\n",
      "\n",
      "\n",
      "### Tiền xử lý dữ liệu\n",
      "\n",
      "Tiền xử lý dữ liệu là bước xử lý không thể thiếu trong các bài toán dịch. Sau khi thu thập được đầy đủ các tập dữ liệu, chúng tôi tiến hành chuẩn hóa. Đầu tiên, chúng tôi thực hiện tách từ trong văn bản, đối với văn bản tiếng Anh thì cần quan tâm tới việc tách các dấu \". , ’ ; ? \" và các kí tự đặc biệt khác ra khỏi các từ trong văn bản. Để thực hiện việc này, chúng tôi sử dụng công cụ tách từ Tokenizer có sẵn trong hệ dịch mã nguồn mở Moses [4] do Koehn và cộng sự phát triển (2007). Đối với tiếng Việt, vì dấu cách không phải là dấu hiệu để phân biệt các từ, mà một từ trong tiếng Việt được cấu tạo bởi một hoặc nhiều âm tiết. Chính vì vậy, để tiến hành tách từ cho văn bản tiếng Việt, chúng tôi sử dụng công cụ tách từ dành riêng cho tiếng Việt khá phổ biến là VnTokenizer [1].\n",
      "\n",
      "Sau đó, chúng tôi thực hiện chuyển tất cả các kí tự hoa trong các tập dữ liệu về dạng kí tự thường và loại bỏ những cặp câu có độ dài quá lớn trong dữ liệu, trong các thực nghiệm này chúng tôi chỉ chọn những câu có độ dài nhỏ hơn 80.\n",
      "\n",
      "### Các thực nghiệm\n",
      "\n",
      "Để huấn luyện các hệ dịch nơ ron, chúng tôi sử dụng công cụ OpenNMT3 [7], đây là hệ dịch mã nguồn mở hoàn thiện, nổi tiếng, được công bố năm 2017 của nhóm [Harvard NLP](https://nlp.seas.harvard.edu/) và SYSTRAN, công cụ này được nhiều người nghiên cứu trong cộng đồng dịch máy sử dụng. Các hệ dịch được huấn luyện với cùng các tham số mặc định, bao gồm hai tầng mạng LSTM với 500 nút ẩn và có sử dụng mô hình attention theo kiến trúc của Thang Luong [8]. Để so sánh, đánh giá chất lượng của các hệ dịch với nhau, chúng tôi sử dụng cách đánh giá tự động dựa vào điểm BLEU [6], đây cũng là cách đánh giá phổ biến trong bài toán dịch máy. Như mô tả ở hình 3:\n",
      "**_Giai đoạn 1:_** Chúng tôi huấn luyện các hệ dịch cơ sở Baseline NMT, các hệ dịch này được huấn luyện với dữ liệu song ngữ thuộc miền tổng quan, nhưng được tối ưu tham số trong các miền dữ liệu khác nhau, cụ thể:\n",
      "\n",
      "  * Hệ dịch **Baseline_G:** Sử dụng tập dữ liệu G_train và G_val _(mô tả trong bảng 1)_ để huấn luyện, hệ dịch cơ sở này được huấn luyện với dữ liệu song ngữ và tối ưu các tham số trong cùng một miền tổng quan.\n",
      "\n",
      "  * Hệ dịch **Baseline_L:** Sử dụng tập dữ liệu G_train và L_val _(mô tả trong bảng 1_ ) để huấn luyện, hệ dịch cơ sở này được huấn luyện với dữ liệu song ngữ thuộc miền tổng quan nhưng các tham số của hệ dịch được tối ưu trong miền pháp lý.\n",
      "\n",
      "\n",
      "Việc lựa chọn hệ dịch có chất lượng bản dịch tốt, để từ đó tiến hành dịch xuôi và tổng hợp được dữ liệu song ngữ có chất lượng tốt. Chúng tôi tiến hành đánh giá, so sánh chất lượng bản dịch của hai hệ dịch cơ sở này khi dịch trong cùng một miền dữ liệu tổng quan và miền dữ liệu pháp lý. Kết quả thử nghiệm được đánh giá thông qua điểm BLEU được thể hiện như bảng 2. Ở bảng 2, ta thấy:\n",
      "\n",
      "  * Khi dịch với cùng tập dữ liệu là G_test thuộc miền tổng quan, hệ dịch Baseline_G cho điểm BLEU = 29,34 trong khi Baseline_L có điểm BLEU = 29,56.\n",
      "\n",
      "  * Khi dịch với cùng tập dữ liệu L_test thuộc miền pháp lý thì hệ dịch Baseline_G cho điểm BLEU = 22,17 và hệ dịch Baseline_L cho điểm BLEU = 23,01.\n",
      "\n",
      "\n",
      "Như vậy, khi hệ dịch cơ sở Baseline_L được tối ưu tham số trong miền pháp lý đã cải tiến được chất lượng của bản dịch khi dịch trong miền pháp lý, cụ thể đã tăng 0.84 điểm BLEU _(điểm BLEU = 23,01 so với 22,17 của hệ dịch Baseline_G)_. Căn cứ vào kết quả so sánh này, chúng tôi lựa chọn hệ dịch cơ sở Baseline_L để thực hiện các bước trong giai đoạn 2.\n",
      "**_Giai đoạn 2:_** Chúng tôi dùng hệ dịch Baseline_L ở trên để dịch tập dữ liệu đơn ngữ gồm 100.000 câu tiếng Anh thuộc miền pháp lý sinh ra bản dịch tương ứng gồm 100.000 câu tiếng Việt.\n",
      "\n",
      "**_Giai đoạn 3:_** Chúng tôi sử dụng cặp dữ liệu đơn ngữ ở giai đoạn 2 _(gồm 100.000 tiếng Anh và bản dịch của nó gồm 100.000 tiếng Việt)_ để huấn luyện hệ dịch Adapt_System, hệ dịch này được tối ưu tham số với tập dữ liệu L_val thuộc miền pháp lý. Các thử nghiệm cho kết quả điểm BLEU = 26,56 khi dịch tập dữ liệu G_test thuộc miền tổng quan, và điểm BLEU = 24,38 khi dịch tập dữ liệu L_test thuộc miền pháp lý.\n",
      "\n",
      "Như vậy, hệ dịch Adapt_System cho chất lượng dịch trong miền pháp lý cao hơn so với các hệ dịch cơ sở Baseline_G và Baseline_L. Cụ thể, điểm BLEU cao hơn 2,21 điểm so với Baseline_G _(cải tiến từ 22,17 điểm tăng lên 24,38 điểm)_ và cao hơn 1,37 điểm so với Baseline_L _(cải tiến từ 23,01 điểm tăng lên 24,38 điểm)._ Các kết quả thử nghiệm được thể hiện trong bảng 2 và sự biến đổi về chất lượng của bản dịch được thể hiện như biểu đồ trong hình 4.\n",
      "\n",
      "Các kết quả thử nghiệm đã cho thấy phương pháp mà chúng tôi đề xuất là cách tiếp cận khả quan, dễ thực hiện và đã cho kết quả dịch khi dịch trong miền pháp lý cải tiến hơn so với hệ dịch cơ sở ban đầu.\n",
      "\n",
      "## KẾT LUẬN\n",
      "\n",
      "Trong bài báo này, chúng tôi đã đề xuất một phương pháp thích ứng miền mới cho dịch máy nơ ron, phương pháp này đặc biệt hiệu quả đối với các miền dữ liệu có ít tài nguyên của cặp ngôn ngữ Anh - Việt, trong các thử nghiệm của chúng tôi, chúng tôi sử dụng dữ liệu thuộc miền pháp lý. Qua thực nghiệm cho thấy, cách tiếp cận này là khả quan, dễ thực hiện và đã cho kết quả dịch có điểm BLEU tăng 2,21 điểm _(từ 22,17 điểm lên 24,38 điểm)._ Như vậy, chất lượng dịch sau khi thích ứng đã có cải tiến hơn so với hệ dịch cơ sở ban đầu.\n",
      "\n",
      "Trong tương lai, chúng tôi sẽ tiến hành thử nghiệm mở rộng thêm trên cả hai chiều dịch đối với một số miền dữ liệu khác, và khảo sát với các tình huống khi dữ liệu đơn ngữ theo miền có sự thay đổi về lượng thì chất lượng dịch của hệ thống lúc này sẽ thay đổi như thế nào, và lượng dữ liệu đơn ngữ này thay đổi như thế nào là vừa đủ đối với từng miền dữ liệu.\n",
      "\n",
      "# TÀI LIỆU THAM KHẢO\n",
      "\n",
      "  1. Phuong-Le Hong, Huyen-Nguyen Thi Minh, Azim Roussanaly and Vinh-Ho Tuong (2008). A Hybrid Approach to Word Segmentation of Vietnamese Texts.In Proceedings of the 2nd International Conference on Language and Automata Theory and Applications, Springer, LNCS 5196.\n",
      "\n",
      "  2. Philipp Koehn and Josh Schroeder. 2007. Experiments in domain adaptation for statistical machine translation. In Proceedings of the Second Workshop on Statistical Machine Translation, pages 224–227, Prague, Czech Republic.\n",
      "\n",
      "\n",
      "  3. Philipp Koehn. 2002. Europarl: A multilingual corpus for evaluation of machine translation. Unpublished, http://www.isi.edu/∼koehn/europarl.\n",
      "\n",
      "  4. P. Koehn, H. Hoang, A. Birch, C. Callison-Burch, M. Federico, N. Bertoldi, B. Cowan, W. Shen, C. Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin, and E. Herbst. 2007. Moses: Open source toolkit for statistical machine translation. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions, pages 177– 180, Prague, Czech Republic.\n",
      "\n",
      "  5. Philipp Koehn. 2017. Neural machine translation. CoRR, abs/1709.07809.\n",
      "\n",
      "  6. Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. BLEU: a method for automatic evaluation of machine translation. In Proceedings of the 40th Annual Meeting of the Association of Computational Linguistics (ACL), pages 311–318, Philadelphia, PA.\n",
      "\n",
      "  7. Guillaume Klein, Yoon Kim, Yuntian Deng, Jean Senellart, Alexander M. Rush. 2017. OpenNMT: Open-Source\n",
      "\n",
      "\n",
      "Toolkit for Neural Machine Translation. Proceedings of AMTA 2018, vol. 1: MT Research Track.\n",
      "\n",
      "  8. Minh-Thang Luong, Hieu Pham, and Christopher D Manning. 2015. [Effective approaches to attention-based neural](https://arxiv.org/pdf/1508.04025.pdf) [machine translation.](https://arxiv.org/pdf/1508.04025.pdf) EMNLP.\n",
      "\n",
      "  9. Nicola Ueffing, Gholamreza Haffari, and Anoop Sarkar. 2007. Semi-supervised model adaptation for statistical machine translation. Machine Translation, 21(2):77–94.\n",
      "\n",
      "  10. Nicola Bertoldi, Marcello Federico. 2009. Domain Adaptation for Statistical Machine Translation with Monolingual Resources. Proceedings of the 4th EACL Workshop on Statistical Machine Translation , pages 182–189.\n",
      "\n",
      "  11. Rico Sennrich, Barry Haddow, and Alexandra Birch. 2016. Improving neural machine translation models with monolingual data. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 86–96, Berlin, Germany, August. Association for Computational Linguistics.\n",
      "\n",
      "\n",
      "##', token_count=9929, start_index=20906, end_index=30835)]\n"
     ]
    }
   ],
   "source": [
    "from chonkie import MarkdownChef\n",
    "# Initialize the chef\n",
    "chef = MarkdownChef()\n",
    "doc = chef.process(\"/data/AIRACE/training_out/Public003/main.md\")\n",
    "print(doc.chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf50ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/agent/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/miniconda3/envs/agent/lib/python3.10/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [01:55<00:00, 38.35s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen3-4B-Instruct-2507\", cache_dir=\"/data/AIRACE/RAG\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen3-4B-Instruct-2507\", cache_dir= \"/data/AIRACE/RAG\")\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0641e3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = '''| Model                                                                                                                                                                    | Size<br><sup>(pixels) | mAP<sup>val<br>50-95 | mAP<sup>val<br>50 | Speed<br><sup>CPU b1<br>(ms) | Speed<br><sup>V100 b1<br>(ms) | Speed<br><sup>V100 b32<br>(ms) | Params<br><sup>(M) | FLOPs<br><sup>@640 (B) |\n",
    "| ------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | --------------------- | -------------------- | ----------------- | ---------------------------- | ----------------------------- | ------------------------------ | ------------------ | ---------------------- |\n",
    "| [YOLOv5n](https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5n.pt)                                                                                       | 640                   | 28.0                 | 45.7              | **45**                       | **6.3**                       | **0.6**                        | **1.9**            | **4.5**                |\n",
    "| [YOLOv5s](https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt)                                                                                       | 640                   | 37.4                 | 56.8              | 98                           | 6.4                           | 0.9                            | 7.2                | 16.5                   |\n",
    "| [YOLOv5m](https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5m.pt)                                                                                       | 640                   | 45.4                 | 64.1              | 224                          | 8.2                           | 1.7                            | 21.2               | 49.0                   |\n",
    "| [YOLOv5l](https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5l.pt)                                                                                       | 640                   | 49.0                 | 67.3              | 430                          | 10.1                          | 2.7                            | 46.5               | 109.1                  |\n",
    "| [YOLOv5x](https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5x.pt)                                                                                       | 640                   | 50.7                 | 68.9              | 766                          | 12.1                          | 4.8                            | 86.7               | 205.7                  |\n",
    "|                                                                                                                                                                          |                       |                      |                   |                              |                               |                                |                    |                        |\n",
    "| [YOLOv5n6](https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5n6.pt)                                                                                     | 1280                  | 36.0                 | 54.4              | 153                          | 8.1                           | 2.1                            | 3.2                | 4.6                    |\n",
    "| [YOLOv5s6](https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s6.pt)                                                                                     | 1280                  | 44.8                 | 63.7              | 385                          | 8.2                           | 3.6                            | 12.6               | 16.8                   |\n",
    "| [YOLOv5m6](https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5m6.pt)                                                                                     | 1280                  | 51.3                 | 69.3              | 887                          | 11.1                          | 6.8                            | 35.7               | 50.0                   |\n",
    "| [YOLOv5l6](https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5l6.pt)                                                                                     | 1280                  | 53.7                 | 71.3              | 1784                         | 15.8                          | 10.5                           | 76.8               | 111.4                  |\n",
    "| [YOLOv5x6](https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5x6.pt)<br>+ [[TTA]](https://docs.ultralytics.com/yolov5/tutorials/test_time_augmentation/) | 1280<br>1536          | 55.0<br>**55.8**     | 72.7<br>**72.7**  | 3136<br>-                    | 26.2<br>-                     | 19.4<br>-                      | 140.7<br>-         | 209.8<br>-             |'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b11d462a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tables' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[1;32m      3\u001b[0m pipe \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-generation\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39mmodel, tokenizer\u001b[38;5;241m=\u001b[39mtokenizer)\n\u001b[1;32m      4\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      5\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBạn là chuyên gia ngôn ngữ có khả năng tổng hợp thông tin từ bảng biểu.\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m----> 6\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHãy viết một đoạn mô tả bảng sau \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mtables\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m đảm bảo các yếu tố sau:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m 1) Câu trả lời bằng tiếng Việt.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m 2) Câu trả lời chỉ có đoạn mô tả bảng bằng text không có thêm phần giải thích, hoặc ký hiệu lạ,..\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m      7\u001b[0m ]\n\u001b[1;32m      8\u001b[0m pipe(messages)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tables' is not defined"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Bạn là chuyên gia ngôn ngữ có khả năng tổng hợp thông tin từ bảng biểu.\"},\n",
    "    {\"role\": \"user\", \"content\": f\"Hãy viết một đoạn mô tả bảng sau {tables} đảm bảo các yếu tố sau:\\n 1) Câu trả lời bằng tiếng Việt.\\n 2) Câu trả lời chỉ có đoạn mô tả bảng bằng text không có thêm phần giải thích, hoặc ký hiệu lạ,..\"},\n",
    "]\n",
    "pipe(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5369f01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings  # ho?c HuggingFaceEmbeddings\n",
    "from langchain.schema import Document\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# -----------------------\n",
    "# 1?? Chu?n b? d? li?u\n",
    "# -----------------------\n",
    "\n",
    "# Gi? s? b?n ?ã có danh sách các Document:\n",
    "# documents = [Document(page_content=text, metadata=metadata), ...]\n",
    "\n",
    "# Ví d? nh?:\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=\"Summary: ?o?n code tính t?ng hai s?.\",\n",
    "        metadata={\"source\": \"file1.py\", \"type\": \"code\", \"full_text\": \"def add(a,b): return a+b\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Summary: b?ng th?ng kê doanh thu n?m 2024.\",\n",
    "        metadata={\"source\": \"report.xlsx\", \"type\": \"table\", \"full_text\": \"| Year | Revenue |\\n| 2024 | 1.2M |\"}\n",
    "    ),\n",
    "]\n",
    "\n",
    "# -----------------------\n",
    "# 2?? T?o embedding & l?u vào FAISS\n",
    "# -----------------------\n",
    "EMBED_MODEL = \"keepitreal/vietnamese-sbert\"\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=EMBED_MODEL) # ho?c HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "vector_db = FAISS.from_documents(documents, embedding_model)\n",
    "\n",
    "# -----------------------\n",
    "# 3?? Truy v?n semantic\n",
    "# -----------------------\n",
    "\n",
    "query = \"doanh thu n?m 2024\"\n",
    "\n",
    "# top_k = s? l??ng context l?y ra\n",
    "results = vector_db.similarity_search(query, k=3)\n",
    "\n",
    "# -----------------------\n",
    "# 4?? X? lý k?t qu? tr? v?\n",
    "# -----------------------\n",
    "\n",
    "contexts = []\n",
    "for doc in results:\n",
    "    # L?y text g?c t? metadata n?u có, fallback v? page_content\n",
    "    text_content = doc.metadata.get(\"full_text\", doc.page_content)\n",
    "    contexts.append({\n",
    "        \"text\": text_content,\n",
    "        \"metadata\": doc.metadata\n",
    "    })\n",
    "\n",
    "# -----------------------\n",
    "# 5?? In ra context ?? dùng cho LLM\n",
    "# -----------------------\n",
    "for i, ctx in enumerate(contexts, start=1):\n",
    "    print(f\"--- Context {i} ---\")\n",
    "    print(f\"Source: {ctx['metadata'].get('source', 'unknown')}\")\n",
    "    print(ctx[\"text\"])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a275901",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3030273/2602696121.py:48: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding = HuggingFaceEmbeddings(model_name=EMBED_MODEL)\n",
      "/opt/miniconda3/envs/agent/lib/python3.10/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "/opt/miniconda3/envs/agent/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.docstore.document import Document\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings  # Ho?c HuggingFaceEmbeddings\n",
    "import os\n",
    "\n",
    "# -----------------------\n",
    "# 1?? Chu?n b? d? li?u\n",
    "# -----------------------\n",
    "EMBED_MODEL = \"keepitreal/vietnamese-sbert\"\n",
    "# Ví d? d? li?u: m?i Document có summary trong page_content,\n",
    "# và n?i dung g?c (code, b?ng, context) trong metadata.\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=\"Summary: ?o?n code tính t?ng hai s?.\",\n",
    "        metadata={\n",
    "            \"source\": \"file1.py\",\n",
    "            \"type\": \"code\",\n",
    "            \"full_text\": \"def add(a, b):\\n    return a + b\"\n",
    "        }\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Summary: b?ng th?ng kê doanh thu n?m 2024.\",\n",
    "        metadata={\n",
    "            \"source\": \"report.xlsx\",\n",
    "            \"type\": \"table\",\n",
    "            \"full_text\": \"| Year | Revenue |\\n| 2024 | 1.2M |\"\n",
    "        }\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Summary: mô t? chi?n l??c marketing quý I.\",\n",
    "        metadata={\n",
    "            \"source\": \"plan.txt\",\n",
    "            \"type\": \"text\",\n",
    "            \"full_text\": \"Chi?n l??c marketing t?p trung vào kênh social media và qu?ng cáo tr? phí.\"\n",
    "        }\n",
    "    )\n",
    "]\n",
    "\n",
    "# -----------------------\n",
    "# 2?? T?o embedding model\n",
    "# -----------------------\n",
    "\n",
    "\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "embedding = HuggingFaceEmbeddings(model_name=EMBED_MODEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07517db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# -----------------------\n",
    "# 3?? T?o (ho?c load) ChromaDB\n",
    "# -----------------------\n",
    "\n",
    "persist_dir = \"./chroma_db_vn\"  # th? m?c l?u d? li?u\n",
    "\n",
    "# vector_db = Chroma.from_documents(\n",
    "#     documents=documents,\n",
    "#     embedding=embedding,\n",
    "#     persist_directory=persist_dir  # ?? có th? load l?i sau\n",
    "# )\n",
    "\n",
    "# # L?u vào ? ??a\n",
    "# vector_db.persist()\n",
    "\n",
    "vector_db = Chroma(\n",
    "    persist_directory=persist_dir,\n",
    "    collection_name=\"vn_chunks\",\n",
    "    embedding_function=embedding\n",
    ")\n",
    "\n",
    "# -----------------------\n",
    "# 4?? Truy v?n semantic similarity\n",
    "# -----------------------\n",
    "\n",
    "query = \" phát hiện đối tượng bằng mô hình YOLOv5s trên nhiều nguồn dữ liệu khác nhau bao gồm webcam, ảnh cục bộ, video, màn hình, thư mục ảnh, tệp văn bản liệt kê đường dẫn ảnh hoặc luồng phát, cũng như các link YouTube, luồng RTSP/RTMP/HTTP\"\n",
    "\n",
    "# Tìm top_k = 3 k?t qu? g?n nh?t\n",
    "results = vector_db.similarity_search(query, k=3)\n",
    "# print(results)\n",
    "\n",
    "# -----------------------\n",
    "# 5?? L?y context + metadata\n",
    "# -----------------------\n",
    "\n",
    "contexts = []\n",
    "for doc in results:\n",
    "    # print(\"----------------\")\n",
    "    # print(doc.metadata)\n",
    "    # print(doc.page_content)\n",
    "    text_content = doc.metadata.get(\"full_text\", doc.page_content)\n",
    "    contexts.append({\n",
    "        \"text\": text_content,\n",
    "        \"metadata\": doc.metadata\n",
    "    })\n",
    "\n",
    "# -----------------------\n",
    "# 6?? In ra k?t qu? context\n",
    "# -----------------------\n",
    "\n",
    "# for i, ctx in enumerate(contexts, start=1):\n",
    "#     print(f\"--- Context {i} ---\")\n",
    "#     print(f\"Source: {ctx['metadata'].get('type', 'unknown')}\")\n",
    "#     print(ctx[\"text\"])\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11443b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Header 1': 'Public_003', 'document_file': '/data/AIRACE/example_folder/main.md'}, {'document_file': '/data/AIRACE/example_folder/main.md', 'Header 1': 'Public_003'}, {'Header 1': 'Public_003', 'document_file': '/data/AIRACE/example_folder/main.md'}, {'Header 1': 'Public_003', 'document_file': '/data/AIRACE/example_folder/main.md'}, {'document_file': '/data/AIRACE/example_folder/main.md', 'Header 1': 'Public_003'}, {'document_file': '/data/AIRACE/example_folder/main.md', 'Header 2': 'GIỚI THIỆU', 'Header 1': 'Nội dung chính'}, {'Header 2': 'GIỚI THIỆU', 'Header 1': 'Nội dung chính', 'document_file': '/data/AIRACE/example_folder/main.md'}, {'Header 2': 'GIỚI THIỆU', 'document_file': '/data/AIRACE/example_folder/main.md', 'Header 1': 'Nội dung chính'}, {'document_file': '/data/AIRACE/example_folder/main.md', 'Header 1': 'Nội dung chính', 'Header 2': 'GIỚI THIỆU'}, {'document_file': '/data/AIRACE/example_folder/main.md', 'Header 2': 'GIỚI THIỆU', 'Header 1': 'Nội dung chính'}, {'Header 1': 'Nội dung chính', 'Header 2': 'GIỚI THIỆU', 'document_file': '/data/AIRACE/example_folder/main.md'}, {'Header 1': 'Nội dung chính', 'document_file': '/data/AIRACE/example_folder/main.md', 'Header 2': 'GIỚI THIỆU'}, {'Header 2': 'GIỚI THIỆU', 'Header 1': 'Nội dung chính', 'document_file': '/data/AIRACE/example_folder/main.md'}, {'Header 2': 'GIỚI THIỆU', 'Header 1': 'Nội dung chính', 'document_file': '/data/AIRACE/example_folder/main.md'}, {'Header 1': 'Nội dung chính', 'Header 2': 'GIỚI THIỆU', 'document_file': '/data/AIRACE/example_folder/main.md'}, {'Header 1': 'Nội dung chính', 'Header 2': 'GIỚI THIỆU', 'document_file': '/data/AIRACE/example_folder/main.md'}, {'Header 2': 'GIỚI THIỆU', 'document_file': '/data/AIRACE/example_folder/main.md', 'Header 1': 'Nội dung chính'}, {'Header 2': 'GIỚI THIỆU', 'Header 1': 'Nội dung chính', 'document_file': '/data/AIRACE/example_folder/main.md'}, {'document_file': '/data/AIRACE/example_folder/main.md', 'Header 1': 'Nội dung chính', 'Header 2': 'CÁC NGHIÊN CỨU LIÊN QUAN'}, {'Header 1': 'Nội dung chính', 'Header 2': 'CÁC NGHIÊN CỨU LIÊN QUAN', 'document_file': '/data/AIRACE/example_folder/main.md'}, {'Header 1': 'Nội dung chính', 'document_file': '/data/AIRACE/example_folder/main.md', 'Header 2': 'CÁC NGHIÊN CỨU LIÊN QUAN'}, {'document_file': '/data/AIRACE/example_folder/main.md', 'Header 2': 'CÁC NGHIÊN CỨU LIÊN QUAN', 'Header 1': 'Nội dung chính'}, {'document_file': '/data/AIRACE/example_folder/main.md', 'Header 1': 'Nội dung chính', 'Header 2': 'CÁC NGHIÊN CỨU LIÊN QUAN'}, {'Header 1': 'Nội dung chính', 'document_file': '/data/AIRACE/example_folder/main.md', 'Header 2': 'CÁC NGHIÊN CỨU LIÊN QUAN'}, {'document_file': '/data/AIRACE/example_folder/main.md', 'Header 2': 'CÁC NGHIÊN CỨU LIÊN QUAN', 'Header 1': 'Nội dung chính'}, {'Header 1': 'Nội dung chính', 'Header 2': 'CÁC NGHIÊN CỨU LIÊN QUAN', 'document_file': '/data/AIRACE/example_folder/main.md'}, {'document_file': '/data/AIRACE/example_folder/main.md', 'Header 2': 'PHƯƠNG PHÁP ĐỀ XUẤT', 'Header 3': 'Tổng quan về dịch máy nơ ron', 'Header 1': 'Nội dung chính'}, {'Header 2': 'PHƯƠNG PHÁP ĐỀ XUẤT', 'Header 3': 'Tổng quan về dịch máy nơ ron', 'document_file': '/data/AIRACE/example_folder/main.md', 'Header 1': 'Nội dung chính'}, {'Header 3': 'Tổng quan về dịch máy nơ ron', 'Header 2': 'PHƯƠNG PHÁP ĐỀ XUẤT', 'Header 1': 'Nội dung chính', 'document_file': '/data/AIRACE/example_folder/main.md'}, {'Header 3': 'Tổng quan về dịch máy nơ ron', 'Header 2': 'PHƯƠNG PHÁP ĐỀ XUẤT', 'document_file': '/data/AIRACE/example_folder/main.md', 'Header 1': 'Nội dung chính'}, {'document_file': '/data/AIRACE/example_folder/main.md', 'Header 1': 'Nội dung chính', 'Header 2': 'PHƯƠNG PHÁP ĐỀ XUẤT', 'Header 3': 'Tổng quan về dịch máy nơ ron'}, {'Header 1': 'Nội dung chính', 'Header 2': 'PHƯƠNG PHÁP ĐỀ XUẤT', 'Header 3': 'Tổng quan về dịch máy nơ ron', 'document_file': '/data/AIRACE/example_folder/main.md'}, {'document_file': '/data/AIRACE/example_folder/main.md', 'Header 1': 'Nội dung chính', 'Header 2': 'PHƯƠNG PHÁP ĐỀ XUẤT', 'Header 3': 'Tổng quan về dịch máy nơ ron'}, {'Header 3': 'Tổng quan về dịch máy nơ ron', 'Header 1': 'Nội dung chính', 'document_file': '/data/AIRACE/example_folder/main.md', 'Header 2': 'PHƯƠNG PHÁP ĐỀ XUẤT'}, {'document_file': '/data/AIRACE/example_folder/main.md', 'Header 2': 'PHƯƠNG PHÁP ĐỀ XUẤT', 'Header 3': 'Tổng quan về dịch máy nơ ron', 'Header 1': 'Nội dung chính'}, {'Header 1': 'Nội dung chính', 'full_context': \"# Run inference using a webcam\\npython detect.py --weights yolov5s.pt --source 0\\n\\n# Run inference on a local image file\\npython detect.py --weights yolov5s.pt --source img.jpg\\n\\n# Run inference on a local video file\\npython detect.py --weights yolov5s.pt --source vid.mp4\\n\\n# Run inference on a screen capture\\npython detect.py --weights yolov5s.pt --source screen\\n\\n# Run inference on a directory of images\\npython detect.py --weights yolov5s.pt --source path/to/images/\\n\\n# Run inference on a text file listing image paths\\npython detect.py --weights yolov5s.pt --source list.txt\\n\\n# Run inference on a text file listing stream URLs\\npython detect.py --weights yolov5s.pt --source list.streams\\n\\n# Run inference using a glob pattern for images\\npython detect.py --weights yolov5s.pt --source 'path/to/*.jpg'\\n\\n# Run inference on a YouTube video URL\\npython detect.py --weights yolov5s.pt --source 'https://youtu.be/LNwODJXcvt4'\\n\\n# Run inference on an RTSP, RTMP, or HTTP stream\\npython detect.py --weights yolov5s.pt --source 'rtsp://example.com/media.mp4'\", 'document_file': '/data/AIRACE/example_folder/main.md', 'Header 2': 'PHƯƠNG PHÁP ĐỀ XUẤT', 'type': 'code', 'Header 3': 'Tổng quan về dịch máy nơ ron'}, {'Header 1': 'Nội dung chính', 'Header 2': 'PHƯƠNG PHÁP ĐỀ XUẤT', 'Header 3': 'Phương pháp đề xuất', 'document_file': '/data/AIRACE/example_folder/main.md'}, {'document_file': '/data/AIRACE/example_folder/main.md', 'Header 2': 'PHƯƠNG PHÁP ĐỀ XUẤT', 'Header 1': 'Nội dung chính', 'Header 3': 'Phương pháp đề xuất'}, {'Header 2': 'PHƯƠNG PHÁP ĐỀ XUẤT', 'Header 3': 'Phương pháp đề xuất', 'document_file': '/data/AIRACE/example_folder/main.md', 'Header 1': 'Nội dung chính'}, {'Header 3': 'Phương pháp đề xuất', 'document_file': '/data/AIRACE/example_folder/main.md', 'Header 1': 'Nội dung chính', 'Header 2': 'PHƯƠNG PHÁP ĐỀ XUẤT'}, {'Header 3': 'Phương pháp đề xuất', 'Header 1': 'Nội dung chính', 'document_file': '/data/AIRACE/example_folder/main.md', 'Header 2': 'PHƯƠNG PHÁP ĐỀ XUẤT'}, {'Header 3': 'Phương pháp đề xuất', 'Header 2': 'PHƯƠNG PHÁP ĐỀ XUẤT', 'document_file': '/data/AIRACE/example_folder/main.md', 'Header 1': 'Nội dung chính'}, {'Header 3': 'Phương pháp đề xuất', 'Header 2': 'PHƯƠNG PHÁP ĐỀ XUẤT', 'Header 1': 'Nội dung chính', 'document_file': '/data/AIRACE/example_folder/main.md'}, {'document_file': '/data/AIRACE/example_folder/main.md', 'Header 1': 'Nội dung chính', 'Header 2': 'PHƯƠNG PHÁP ĐỀ XUẤT', 'Header 3': 'Phương pháp đề xuất'}, {'Header 1': 'Nội dung chính', 'Header 2': 'PHƯƠNG PHÁP ĐỀ XUẤT', 'document_file': '/data/AIRACE/example_folder/main.md', 'Header 3': 'Phương pháp đề xuất'}, {'Header 3': 'Phương pháp đề xuất', 'document_file': '/data/AIRACE/example_folder/main.md', 'Header 2': 'PHƯƠNG PHÁP ĐỀ XUẤT', 'Header 1': 'Nội dung chính'}, {'document_file': '/data/AIRACE/example_folder/main.md', 'Header 1': 'Nội dung chính', 'Header 2': 'THỰC NGHIỆM VÀ KẾT QUẢ'}, {'Header 1': 'Nội dung chính', 'document_file': '/data/AIRACE/example_folder/main.md', 'Header 2': 'THỰC NGHIỆM VÀ KẾT QUẢ'}, {'document_file': '/data/AIRACE/example_folder/main.md', 'Header 2': 'THỰC NGHIỆM VÀ KẾT QUẢ', 'Header 1': 'Nội dung chính'}, {'document_file': '/data/AIRACE/example_folder/main.md', 'Header 2': 'THỰC NGHIỆM VÀ KẾT QUẢ', 'Header 1': 'Nội dung chính'}, {'Header 2': 'THỰC NGHIỆM VÀ KẾT QUẢ', 'Header 1': 'Nội dung chính', 'document_file': '/data/AIRACE/example_folder/main.md'}, {'Header 2': 'THỰC NGHIỆM VÀ KẾT QUẢ', 'document_file': '/data/AIRACE/example_folder/main.md', 'type': 'table', 'Header 1': 'Nội dung chính', 'full_context': '| Model                                                                                                                                                                    | Size<br><sup>(pixels) | mAP<sup>val<br>50-95 | mAP<sup>val<br>50 | Speed<br><sup>CPU b1<br>(ms) | Speed<br><sup>V100 b1<br>(ms) | Speed<br><sup>V100 b32<br>(ms) | Params<br><sup>(M) | FLOPs<br><sup>@640 (B) |\\n| ------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | --------------------- | -------------------- | ----------------- | ---------------------------- | ----------------------------- | ------------------------------ | ------------------ | ---------------------- |\\n| [YOLOv5n](https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5n.pt)                                                                                       | 640                   | 28.0                 | 45.7              | **45**                       | **6.3**                       | **0.6**                        | **1.9**            | **4.5**                |\\n| [YOLOv5s](https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt)                                                                                       | 640                   | 37.4                 | 56.8              | 98                           | 6.4                           | 0.9                            | 7.2                | 16.5                   |\\n| [YOLOv5m](https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5m.pt)                                                                                       | 640                   | 45.4                 | 64.1              | 224                          | 8.2                           | 1.7                            | 21.2               | 49.0                   |\\n| [YOLOv5l](https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5l.pt)                                                                                       | 640                   | 49.0                 | 67.3              | 430                          | 10.1                          | 2.7                            | 46.5               | 109.1                  |\\n| [YOLOv5x](https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5x.pt)                                                                                       | 640                   | 50.7                 | 68.9              | 766                          | 12.1                          | 4.8                            | 86.7               | 205.7                  |\\n|                                                                                                                                                                          |                       |                      |                   |                              |                               |                                |                    |                        |\\n| [YOLOv5n6](https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5n6.pt)                                                                                     | 1280                  | 36.0                 | 54.4              | 153                          | 8.1                           | 2.1                            | 3.2                | 4.6                    |\\n| [YOLOv5s6](https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s6.pt)                                                                                     | 1280                  | 44.8                 | 63.7              | 385                          | 8.2                           | 3.6                            | 12.6               | 16.8                   |\\n| [YOLOv5m6](https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5m6.pt)                                                                                     | 1280                  | 51.3                 | 69.3              | 887                          | 11.1                          | 6.8                            | 35.7               | 50.0                   |\\n| [YOLOv5l6](https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5l6.pt)                                                                                     | 1280                  | 53.7                 | 71.3              | 1784                         | 15.8                          | 10.5                           | 76.8               | 111.4                  |\\n| [YOLOv5x6](https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5x6.pt)<br>+ [[TTA]](https://docs.ultralytics.com/yolov5/tutorials/test_time_augmentation/) | 1280<br>1536          | 55.0<br>**55.8**     | 72.7<br>**72.7**  | 3136<br>-                    | 26.2<br>-                     | 19.4<br>-                      | 140.7<br>-         | 209.8<br>-             |  \\n'}, {'Header 2': 'THỰC NGHIỆM VÀ KẾT QUẢ', 'Header 1': 'Nội dung chính', 'document_file': '/data/AIRACE/example_folder/main.md', 'Header 3': 'Dữ liệu'}, {'Header 3': 'Thống kê dữ liệu', 'Header 1': 'Nội dung chính', 'Header 2': 'THỰC NGHIỆM VÀ KẾT QUẢ', 'document_file': '/data/AIRACE/example_folder/main.md'}, {'Header 2': 'THỰC NGHIỆM VÀ KẾT QUẢ', 'document_file': '/data/AIRACE/example_folder/main.md', 'Header 3': 'Thống kê dữ liệu', 'Header 1': 'Nội dung chính'}, {'Header 1': 'Nội dung chính', 'Header 3': 'Thống kê dữ liệu', 'document_file': '/data/AIRACE/example_folder/main.md', 'Header 2': 'THỰC NGHIỆM VÀ KẾT QUẢ'}, {'document_file': '/data/AIRACE/example_folder/main.md', 'Header 1': 'Nội dung chính', 'Header 3': 'Tiền xử lý dữ liệu', 'Header 2': 'THỰC NGHIỆM VÀ KẾT QUẢ'}, {'Header 1': 'Nội dung chính', 'document_file': '/data/AIRACE/example_folder/main.md', 'Header 3': 'Tiền xử lý dữ liệu', 'Header 2': 'THỰC NGHIỆM VÀ KẾT QUẢ'}, {'Header 2': 'THỰC NGHIỆM VÀ KẾT QUẢ', 'document_file': '/data/AIRACE/example_folder/main.md', 'Header 3': 'Tiền xử lý dữ liệu', 'Header 1': 'Nội dung chính'}, {'document_file': '/data/AIRACE/example_folder/main.md', 'Header 1': 'Nội dung chính', 'Header 3': 'Các thực nghiệm', 'Header 2': 'THỰC NGHIỆM VÀ KẾT QUẢ'}, {'document_file': '/data/AIRACE/example_folder/main.md', 'Header 3': 'Các thực nghiệm', 'Header 2': 'THỰC NGHIỆM VÀ KẾT QUẢ', 'Header 1': 'Nội dung chính'}, {'Header 1': 'Nội dung chính', 'document_file': '/data/AIRACE/example_folder/main.md', 'Header 3': 'Các thực nghiệm', 'Header 2': 'THỰC NGHIỆM VÀ KẾT QUẢ'}, {'document_file': '/data/AIRACE/example_folder/main.md', 'Header 2': 'THỰC NGHIỆM VÀ KẾT QUẢ', 'Header 3': 'Các thực nghiệm', 'Header 1': 'Nội dung chính'}, {'document_file': '/data/AIRACE/example_folder/main.md', 'Header 1': 'Nội dung chính', 'Header 2': 'THỰC NGHIỆM VÀ KẾT QUẢ', 'Header 3': 'Các thực nghiệm'}, {'document_file': '/data/AIRACE/example_folder/main.md', 'Header 1': 'Nội dung chính', 'Header 2': 'THỰC NGHIỆM VÀ KẾT QUẢ', 'Header 3': 'Các thực nghiệm'}, {'Header 2': 'THỰC NGHIỆM VÀ KẾT QUẢ', 'Header 1': 'Nội dung chính', 'Header 3': 'Các thực nghiệm', 'document_file': '/data/AIRACE/example_folder/main.md'}, {'document_file': '/data/AIRACE/example_folder/main.md', 'Header 2': 'THỰC NGHIỆM VÀ KẾT QUẢ', 'Header 1': 'Nội dung chính', 'Header 3': 'Các thực nghiệm'}, {'Header 1': 'Nội dung chính', 'document_file': '/data/AIRACE/example_folder/main.md', 'Header 3': 'Các thực nghiệm', 'Header 2': 'THỰC NGHIỆM VÀ KẾT QUẢ'}, {'Header 1': 'Nội dung chính', 'Header 3': 'Các thực nghiệm', 'Header 2': 'THỰC NGHIỆM VÀ KẾT QUẢ', 'document_file': '/data/AIRACE/example_folder/main.md'}, {'Header 3': 'Các thực nghiệm', 'Header 1': 'Nội dung chính', 'Header 2': 'THỰC NGHIỆM VÀ KẾT QUẢ', 'document_file': '/data/AIRACE/example_folder/main.md'}, {'Header 1': 'Nội dung chính', 'document_file': '/data/AIRACE/example_folder/main.md', 'Header 2': 'KẾT LUẬN'}, {'document_file': '/data/AIRACE/example_folder/main.md', 'Header 1': 'Nội dung chính', 'Header 2': 'KẾT LUẬN'}, {'Header 2': 'KẾT LUẬN', 'document_file': '/data/AIRACE/example_folder/main.md', 'Header 1': 'Nội dung chính'}, {'Header 1': 'TÀI LIỆU THAM KHẢO', 'document_file': '/data/AIRACE/example_folder/main.md'}, {'Header 1': 'TÀI LIỆU THAM KHẢO', 'document_file': '/data/AIRACE/example_folder/main.md'}, {'Header 1': 'TÀI LIỆU THAM KHẢO', 'document_file': '/data/AIRACE/example_folder/main.md'}, {'Header 1': 'TÀI LIỆU THAM KHẢO', 'document_file': '/data/AIRACE/example_folder/main.md'}, {'Header 1': 'TÀI LIỆU THAM KHẢO', 'document_file': '/data/AIRACE/example_folder/main.md'}, {'document_file': '/data/AIRACE/example_folder/main.md', 'Header 1': 'TÀI LIỆU THAM KHẢO'}, {'Header 1': 'TÀI LIỆU THAM KHẢO', 'document_file': '/data/AIRACE/example_folder/main.md'}]\n"
     ]
    }
   ],
   "source": [
    "print(vector_db.get()[\"metadatas\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9492840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 2, 'b': 2}\n"
     ]
    }
   ],
   "source": [
    "a = {\"a\":1, \"b\":2}\n",
    "a.update({\"a\":2, \"b\":2})\n",
    "print(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
